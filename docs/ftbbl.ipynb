{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea00a41a",
   "metadata": {},
   "source": [
    "# Feature Testbed Benchmark Library\n",
    "\n",
    "The Feature Testbed and Benchmarking Library (FTb/BL) consists of a series of workflow tools in `cirq_google.workflow` and a library of application-inspired algorithms conforming to those specifications living in ReCirq.\n",
    "\n",
    "Computer code can serve as the intermediary language between algorithms researchers, software developers, and providers of quantum hardware -- each of whom have their own unique domain expertise. Higher-order abstraction in Quantum Executables can support higher-order functionality in our Quantum Runtime.\n",
    "\n",
    "By architecting features, tools, and techniques to be part of a well specified runtime we can:\n",
    " - Easily run experiments (\"A/B testing\") on the impact of features by toggling them in the runtime and running against a full library of applications.\n",
    " - Create a clear specification for how to leverage a feature, tool, or technique in our library of applications.\n",
    " - Mock out runtime features for ease of testing without consuming the scarce resource of quantum computer time.\n",
    " \n",
    "![Overview](./images/ftbbl-overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1fcbd4",
   "metadata": {},
   "source": [
    "## Algorithmic Benchmark Library\n",
    "\n",
    "The algorithmic benchmark library is a collection of quantum executables that probe different aspects of a quantum computer's performance. Each benchmark is based off of an algorithm of interest and operates on > 2 qubits (in contrast to traditional 1- and 2-qubit fidelity metrics).\n",
    "\n",
    "We use the library card catalog in `recirq.algorithmic_benchmark_library` to get a description of each algorithmic benchmark.\n",
    "\n",
    "![Algorithmic Benchmark Library Card Catalog](./images/ftbbl-catalog.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa69118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recirq.algorithmic_benchmark_library as algos\n",
    "from IPython.display import display\n",
    "\n",
    "for algo in algos.BENCHMARKS:\n",
    "    display(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72765c1f",
   "metadata": {},
   "source": [
    "### Select an example benchmark using `executable_family`\n",
    "\n",
    "Each benchmark has a name (e.g. \"loschmidt.tilted_square_lattice\") and a domain (e.g. this benchmark is inspired by the [OTOC Experiment](https://quantumai.google/cirq/experiments/otoc) so it is given the domain of \"recirq.otoc\"). We combine these two properties to give the `executable_family` string, which serves as a globally-unique identifier for each benchmark. In ReCirq, the `executable_family` is the Python module path where the relevant code can be found.\n",
    "\n",
    "We'll seelct the \"recirq.otoc.loschmidt.tilted_square_lattice\" benchmark by querying the card catalog using this unique `executable_family` identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6559da",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = algos.get_algo_benchmark_by_executable_family(\n",
    "    executable_family='recirq.otoc.loschmidt.tilted_square_lattice')\n",
    "print(type(algo))\n",
    "algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# In ReCirq, the `executable_family` is the Python module path where\n",
    "# the relevant code can be found.\n",
    "algo_src_dir = Path('..') / algo.executable_family.replace('.', '/')\n",
    "algo_src_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd3932",
   "metadata": {},
   "source": [
    "### Each `AlgorithimBenchmark` has a collection of `BenchmarkConfig`s\n",
    "\n",
    "An algorithmic benchmark defines a class of quantum executables. Often times the specific size, shape, depth or other properties is left as a parameter. For each benchmark, we have a collection of `BenchmarkConfig`s that fully specify what to run and can be run repeatedly for controlled comparison over time or between processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config in algo.configs:\n",
    "    print(config.full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f8137",
   "metadata": {},
   "source": [
    "We'll select the `small-cz-v1` configuration, as described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38025d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = algo.get_config_by_full_name('loschmidt.tilted_square_lattice.small-cz-v1')\n",
    "print(config.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d298924",
   "metadata": {},
   "source": [
    "A benchmark has three steps:\n",
    " 1. Executable generation\n",
    " 2. Execution\n",
    " 3. Analysis\n",
    " \n",
    "Usually, these steps are done in order but independently and with differing frequencies. For a robust benchmark, executable generation should likely be done once and the serialized `QuantumExecutableGroup` cached and re-used for subsequent executions. Execution should happen on a regular cadence for historical data or as part of an A/B test for trialing different runtime configuraiton options. Analysis can happen at any moment and may incorperate the latest data or a collection of datasets across time, processors, or runtime configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdbd677",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2296df",
   "metadata": {},
   "source": [
    "## Step 1: Executable Generation\n",
    "\n",
    "Here, we generate a `QuantumExecutableGroup` for a given range of parameters. This step is usually done once for each `BenchmarkConfig` and the serialized result is saved and re-used for execution. We use a short python file more like a configuration file than a script to commit the parameters for a particular config. The filename can be found as `config.gen_script`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to show scripts from the ReCirq repository for comparison\n",
    "from IPython.display import Code, HTML\n",
    "\n",
    "def show_python_script(path: Path):\n",
    "    with path.open() as f:\n",
    "        contents = f.read()\n",
    "\n",
    "    display(HTML(f\"<u>The contents of {path}:</u>\"))\n",
    "    display(Code(contents[contents.find('import'):], language='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_python_script(algo_src_dir / config.gen_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02665c6",
   "metadata": {},
   "source": [
    "We've copied the important bit into the cell below so you can execute it within this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from recirq.otoc.loschmidt.tilted_square_lattice import get_all_tilted_square_lattice_executables\n",
    "\n",
    "exes = get_all_tilted_square_lattice_executables(\n",
    "    min_side_length=2, max_side_length=3, side_length_step=1,\n",
    "    n_instances=3,\n",
    "    macrocycle_depths=np.arange(0, 4 + 1, 1),\n",
    "    twoq_gate_name='cz',\n",
    "    seed=52,\n",
    ")\n",
    "len(exes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f4c854",
   "metadata": {},
   "source": [
    "## Step 2: Execution\n",
    "\n",
    "The `QuantumExecutableGroup` for our benchmark defines _what_ to run. Now we configure _how_ to run it. This is done with a `QuantumRuntimeConfiguration`.\n",
    "\n",
    "We specify which processor to use (here: a simulated one. Try changing to `EngineProcessorRecord` to run on a real device), how to map the \"logical\" qubit identities in the problem to physical qubits (here: randomly), and how to set the random number generator's seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5423c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirq_google.workflow import (\n",
    "    QuantumRuntimeConfiguration, \n",
    "    SimulatedProcessorWithLocalDeviceRecord,\n",
    "    EngineProcessorRecord,\n",
    "    RandomDevicePlacer\n",
    ")\n",
    "\n",
    "rt_config = QuantumRuntimeConfiguration(\n",
    "    processor_record=SimulatedProcessorWithLocalDeviceRecord('rainbow', noise_strength=0.005),\n",
    "    qubit_placer=RandomDevicePlacer(),\n",
    "    random_seed=52,\n",
    ")\n",
    "rt_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374cd70",
   "metadata": {},
   "source": [
    "Again, we use a short Python file in the repository to commit the configuration options for a particular config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_python_script(algo_src_dir / 'run-simulator.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6f107",
   "metadata": {},
   "source": [
    "Usually, we're very careful about saving everthing in a structured way relative to a `base_data_dir`. Since this notebook is run interactively, we'll make a temporary directory to serve as our `base_data_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f44d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "base_data_dir = tempfile.mkdtemp()\n",
    "base_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82179e3",
   "metadata": {},
   "source": [
    "Actual execution is as simple as calling `execute` once the runtime configuration and executables are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3525eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirq_google.workflow import execute\n",
    "raw_results = execute(rt_config, exes, base_data_dir=base_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a52c7c3",
   "metadata": {},
   "source": [
    "Since we didn't input our own, a random `run_id` is generated for us. The run_ids must be unique within a data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = raw_results.shared_runtime_info.run_id\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd9675",
   "metadata": {},
   "source": [
    "## Step 3: Analysis and Plotting\n",
    "\n",
    "Finally, we can analyze one or more datasets and generate plots. Since we've decoupled problem generation and execution from this step you can slice and dice your data any way you want. Usually, analysis routines will use the accompanying `analysis` module for helper function and do much of the `pd.DataFrame` and `matplotlib` munging interactively in a Jupyter notebook. One of the plots from `plots.ipynb` is reproduced here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c2a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recirq.otoc.loschmidt.tilted_square_lattice.analysis as analysis\n",
    "import cirq_google as cg\n",
    "import pandas as pd\n",
    "\n",
    "raw_results = cg.ExecutableGroupResultFilesystemRecord.from_json(run_id=run_id, base_data_dir=base_data_dir)\\\n",
    "                    .load(base_data_dir=base_data_dir)\n",
    "df = analysis.loschmidt_results_to_dataframe(raw_results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_depth_df, vs_depth_gb_cols = analysis.agg_vs_macrocycle_depth(df)\n",
    "fit_df, exp_ansatz = analysis.fit_vs_macrocycle_depth(df)\n",
    "total_df = pd.merge(vs_depth_df, fit_df, on=vs_depth_gb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff91c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "colors = plt.get_cmap('tab10')\n",
    "\n",
    "for i, row in total_df.iterrows():\n",
    "    plt.errorbar(\n",
    "        x=row['macrocycle_depth'],\n",
    "        y=row['success_probability_mean'],\n",
    "        yerr=row['success_probability_std'],\n",
    "        marker='o', capsize=5, ls='',\n",
    "        color=colors(i),\n",
    "        label=f'{row[\"width\"]}x{row[\"height\"]} ({row[\"n_qubits\"]}q) {row[\"processor_str\"]}; f={row[\"f\"]:.3f}'\n",
    "    )\n",
    "    \n",
    "    xx = np.linspace(np.min(row['macrocycle_depth']), np.max(row['macrocycle_depth']))\n",
    "    yy = exp_ansatz(xx, a=row['a'], f=row['f'])\n",
    "    plt.plot(xx, yy, ls='--', color=colors(i))\n",
    "    \n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Macrocycle Depth')\n",
    "plt.ylabel('Success Probability')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b73a3",
   "metadata": {},
   "source": [
    "## Appendix: `QuantumExecutable` and `ExecutableSpec`\n",
    "\n",
    "Each `QuantumExecutable` fully specifies the quantum program to be run, but as high-level as possible. The most familiar part is `circuit: cirq.Circuit`, but the executable also includes measurement (i.e. repetitions) information, sweep parameters, and other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "exe = exes.executables[0]\n",
    "\n",
    "import dataclasses\n",
    "print('exe fields:')\n",
    "print([f.name for f in dataclasses.fields(exe)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99681bf",
   "metadata": {},
   "source": [
    "Unlike the other members, `QuantumExectutable.spec` is a back-reference to the `ExecutableSpec` corresponding to this executable. Here, it is a `TiltedSquareLatticeLoschmidtSpec` which derives from the `ExecutableSpec` base class. There is a 1:1 correspondance between an algorithmic benchmark and one of these classes. In contrast to the executable, the spec contains the set of parameters relevant to the application domain that specify how to construct the executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.spec_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958098f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exe.spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ab887",
   "metadata": {},
   "source": [
    "Below, we re-create the executable using just the `spec`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf60381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recirq.otoc.loschmidt.tilted_square_lattice import tilted_square_lattice_spec_to_exe\n",
    "\n",
    "exe2 = tilted_square_lattice_spec_to_exe(exe.spec, rs=np.random.RandomState(52))\n",
    "exe == exe2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
